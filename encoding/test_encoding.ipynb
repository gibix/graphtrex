{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proper encoding for post titles ###\n",
    "\n",
    "In this notebook we will try to check which word encoding can better fit the datasets that will be present in different FBTrex experiments.\n",
    "\n",
    "Here the idea is to try to use as input a word representation of each post and check if it's possibile to guess the source of the post.\n",
    "\n",
    "As long as the only piece of information at our disposition will be the post title we have to rely on it for text analysis.\n",
    "\n",
    "In this sense a clear underststanding of the proper encoding will be critical for future anaytics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random as rnd\n",
    "\n",
    "import csv\n",
    "\n",
    "#Filename is hardcoded\n",
    "filename = \"fbtrex-French2017.csv\"\n",
    "filelength = 65870"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import a word frequency list. File is formatted to contain one word per line\n",
    "\n",
    "def frequency_list(filename):\n",
    "    vec = []\n",
    "    fh = open(filename,'r')\n",
    "    for line in fh.readlines():\n",
    "        vec.append(line)\n",
    "    fh.close()\n",
    "    return vec\n",
    "\n",
    "#Clear from a list of words the most common one from the previous list\n",
    "#Ths should be optimized using a tf-idf function\n",
    "\n",
    "def clear_title(s, voc):\n",
    "    for idx,word in enumerate(s):\n",
    "        if(word in voc):\n",
    "            del s[idx]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_list = 'top100french.csv'\n",
    "most_common_french = frequency_list(word_list)\n",
    "\n",
    "##A canonical example would be to set the training set as the 80% of the \n",
    "##dataset and 20% for the test test. In this way we get the number of \n",
    "##lines in the file\n",
    "\n",
    "flag = 0\n",
    "\n",
    "def vectorize_french(fh, filelength):\n",
    "    \n",
    "    training_set = {}\n",
    "    test_set = {}\n",
    "    \n",
    "    for line in fh.readlines():\n",
    "    \n",
    "        #with this line we skip commas inside strings\n",
    "        line = list(csv.reader(line, skipinitialspace=True))\n",
    "                \n",
    "        #Unfortunately all commas will be saved as separeted elements\n",
    "        # in the list, we can get over this by just considering 2*idx\n",
    "        #where idx is the usual index in the csv\n",
    "        \n",
    "        source = line[20]\n",
    "        title = ''.join(line[22])\n",
    "\n",
    "        title = clear_title(title, most_common_french)\n",
    "\n",
    "        \n",
    "        if flag < (filelength * 0.8):\n",
    "            \n",
    "            training_set[title] = source\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            test_set[title] = source\n",
    "            \n",
    "        flag += 1\n",
    "\n",
    "    return training_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fh = open(filename, 'r')\n",
    "fh.readline()\n",
    "\n",
    "## This parameter defines the size of the training and test datasets \n",
    "rho = 0.8\n",
    "\n",
    "rnd.seed(1)\n",
    "\n",
    "training_set, test_set = vectorize_french(fh, filelength)\n",
    "\n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this step we have "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3862 3050\n"
     ]
    }
   ],
   "source": [
    "print len(training_set), len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-4062229c0b6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type"
     ]
    }
   ],
   "source": [
    "#print test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
