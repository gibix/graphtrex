{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proper encoding for post titles ###\n",
    "\n",
    "In this notebook we will try to check which word encoding can better fit the datasets that will be present in different FBTrex experiments.\n",
    "\n",
    "Here the idea is to try to use as input a word representation of each post and check if it's possibile to guess the source of the post.\n",
    "\n",
    "As long as the only piece of information at our disposition will be the post title we have to rely on it for text analysis.\n",
    "\n",
    "In this sense a clear underststanding of the proper encoding will be critical for future anaytics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random as rnd\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import a word frequency list. File is formatted to contain one word per line\n",
    "def frequency_list(filename):\n",
    "    vec = []\n",
    "    fh = open(filename,'r')\n",
    "    for line in fh.readlines():\n",
    "        vec.append(line)\n",
    "    fh.close()\n",
    "    return vec\n",
    "#Clear from a list of words the most common one from the previous list\n",
    "\n",
    "def clear_title(s, voc):\n",
    "    for idx,word in enumerate(s):\n",
    "        if(word in voc):\n",
    "            del s[idx]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'top100french.csv'\n",
    "most_common_french = frequency_list(filename)\n",
    "\n",
    "def vectorize_french(fh, rho = 0.8):\n",
    "    \n",
    "    training_set = {}\n",
    "    test_set = {}\n",
    "    \n",
    "    for line in fh.readlines():\n",
    "    \n",
    "        #with this line we skip commas inside strings\n",
    "        line = list(csv.reader(line, skipinitialspace=True))\n",
    "        \n",
    "        #Unfortunately all commas will be saved as separeted elements\n",
    "        # in the list, we can get over this by just considering 2*idx\n",
    "        #where idx is the usual index in the csv\n",
    "        \n",
    "        source = line[20]\n",
    "        title = line[22]\n",
    "\n",
    "        if rnd.random < rho:\n",
    "            \n",
    "            training_set[title] = source\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            test_set[title] = source\n",
    "\n",
    "    return training_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-c74e677ce882>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mrho\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtraining_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorize_french\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-4a7ee6c96a8b>\u001b[0m in \u001b[0;36mvectorize_french\u001b[0;34m(fh, rho)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mtest_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtraining_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "filename = \"French2017-sample.csv\"\n",
    "\n",
    "fh = open(filename, 'r')\n",
    "fh.readline()\n",
    "\n",
    "## This parameter defines the size of the training and test datasets \n",
    "rho = 0.8\n",
    "\n",
    "training_set, test_set = vectorize_french(fh, rho)\n",
    "\n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
